{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RecoGym Bandit Based Popularity Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Action dict:\n",
    "```\n",
    "t    = time\n",
    "u    = user\n",
    "a    = action (int representing product in range(0, num_products) )\n",
    "ps   = 1 / num_products\n",
    "ps-a = array of probabilities (floats [0, 1]), 1 for every product\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BanditAgentA - Reinforcement like\n",
    "Every product starts with uniform probability of getting recommended. \n",
    "\n",
    "1. Whenever a product is clicked, this probability increases significantly. (= reward)\n",
    "2. Whenever a product is shown but not clicked, this probability decreases slightly. (= punishment)\n",
    "\n",
    "Since multipliers are used, the second click on a product is rewarded more than the 1st click (assuming the first click brought it above uniform probability) Likewise, additional punishments will get smaller and smaller in absolute numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alp/.local/lib/python3.6/site-packages/recogym/agents/__init__.py:32: UserWarning: Agents Bandit MF Square, Organic MF Square and NN IPS are not available since torch cannot be imported. Install it with `pip install torch` and test it with `python -c \"import torch\"`\n",
      "  warnings.warn('Agents Bandit MF Square, Organic MF Square and NN IPS are not available '\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from random import choices\n",
    "from recogym.agents import Agent\n",
    "\n",
    "# Define an Agent class.\n",
    "class BanditAgentA(Agent):\n",
    "    def __init__(self, config):\n",
    "        # Set number of products as an attribute of the Agent.\n",
    "        super(BanditAgentA, self).__init__(config)\n",
    "\n",
    "        self.product_weights = np.ones(self.config.num_products)\n",
    "        self.factor_reward = 1.99\n",
    "        self.factor_punish = 1.01\n",
    "\n",
    "\n",
    "    def train(self, observation, action, reward, done):\n",
    "        \"\"\"Train method learns from a tuple of data.\n",
    "            this method can be called for offline or online learning\"\"\"\n",
    "\n",
    "        # Reward good bandits, punish bad ones\n",
    "        # This is identical to: \n",
    "        # 1 * 1.99**clicks * 1.01**-(views - clicks)\n",
    "        if reward:\n",
    "            if reward == 1:\n",
    "                # Reward clicks\n",
    "                self.product_weights[action['a']] *= self.factor_reward\n",
    "            else:\n",
    "                # Punish views without click\n",
    "                self.product_weights[action['a']] /= self.factor_punish\n",
    "\n",
    "            \n",
    "    def act(self, observation, reward, done):\n",
    "        \"\"\"Act method returns an action based on current observation and past\n",
    "            history\"\"\"\n",
    "\n",
    "        # Choosing action randomly in proportion to bandit feedback\n",
    "        action = choices(range(self.config.num_products), weights=self.product_weights, k=1).pop()\n",
    "\n",
    "        return {\n",
    "            **super().act(observation, reward, done),\n",
    "            **{\n",
    "                'a': action,\n",
    "                'ps': self.product_weights[action] / sum(self.product_weights),\n",
    "                'ps-a': self.product_weights / sum(self.product_weights)\n",
    "            }\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BanditAgentB - Click-through rate based\n",
    "Recommends based on frequency clicked vs frequency shown with a minimum (average) probability for those products that have never been shown. The \"average\" used is the median CTR of the RandomAgent. (~ 1.1450%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'recogym'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-c55c4afc5b47>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#from numpy.random import choice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mrandom\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mchoices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mrecogym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magents\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAgent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Define an Agent class.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'recogym'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "#from numpy.random import choice\n",
    "from random import choices\n",
    "from recogym.agents import Agent\n",
    "\n",
    "# Define an Agent class.\n",
    "class BanditAgentB(Agent):\n",
    "    def __init__(self, config):\n",
    "        # Set number of products as an attribute of the Agent.\n",
    "        super(BanditAgentB, self).__init__(config)\n",
    "        \n",
    "        # Array: for every product store [# times viewed, #times clicked]\n",
    "        self.bandit_stats = np.zeros((self.config.num_products, 2), dtype=int)\n",
    "\n",
    "\n",
    "    def train(self, observation, action, reward, done):\n",
    "        \"\"\"Train method learns from a tuple of data.\n",
    "            this method can be called for offline or online learning\"\"\"\n",
    "        # Store bandit stats if not organic\n",
    "        if reward:\n",
    "            # If there is not None, there was a view\n",
    "            self.bandit_stats[action['a']][0] += 1\n",
    "            \n",
    "            # If reward == 1, there was a click\n",
    "            self.bandit_stats[action['a']][1] += reward\n",
    "\n",
    "            \n",
    "    def act(self, observation, reward, done):\n",
    "        \"\"\"Act method returns an action based on current observation and past\n",
    "            history\"\"\"\n",
    "\n",
    "        # Transform stats into a click-through ratio (CTR) and make a recommendation where products with a\n",
    "        # higher CTR also have a higher probability to get recommended.\n",
    "        ctrs = [(0.011450 if views == 0 else clicks/views) for views,clicks in self.bandit_stats]\n",
    "        \n",
    "        # Recommend randomly, the higher the clicks/views ratio \n",
    "        action = choices(range(self.config.num_products), weights=ctrs, k=1).pop()\n",
    "\n",
    "        return {\n",
    "            **super().act(observation, reward, done),\n",
    "            **{\n",
    "                'a': action,\n",
    "                'ps': ctrs[action] / sum(ctrs),\n",
    "                'ps-a': ctrs / sum(ctrs)\n",
    "            }\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bandit Agent - Keeps track of number of clicks and recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An agent that for each prodcut keeps track of number of recommendations and the number of clicks obtained. Recommendations are made based on thresholds for number of recommendations and number of clicks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BanditAgentRecFreq(Agent):\n",
    "    def __init__(self, config):\n",
    "        # Set number of products as an attribute of the Agent.\n",
    "        super(BanditAgentRecFreq, self).__init__(config)\n",
    "\n",
    "        self.product_weights = np.ones(self.config.num_products)\n",
    "        self.recommend_freq = np.zeros((self.config.num_products, 2))\n",
    "        self.factor_reward = 1.99\n",
    "        self.factor_punish = 1.01\n",
    "\n",
    "    def train(self, observation, action, reward, done):\n",
    "        \"\"\"Train method learns from a tuple of data.\n",
    "            this method can be called for offline or online learning\"\"\"\n",
    "        if action:\n",
    "            self.recommend_freq[action[\"a\"]][0] += 1\n",
    "            \n",
    "        # Reward good bandits, punish bad ones\n",
    "        if reward:\n",
    "            if reward == 1:\n",
    "                self.product_weights[action[\"a\"]] *= self.factor_reward\n",
    "                self.recommend_freq[action[\"a\"]][1] += 1\n",
    "            else:\n",
    "                self.product_weights[action[\"a\"]] /= self.factor_punish\n",
    "\n",
    "            \n",
    "    def act(self, observation, reward, done):\n",
    "        \"\"\"Act method returns an action based on current observation and past\n",
    "            history\"\"\"\n",
    "\n",
    "        # Choosing action randomly in proportion to bandit feedback\n",
    "        action = choices(range(self.config.num_products), weights=self.product_weights, k=1).pop()\n",
    "        \n",
    "        recommend_freq_med = np.median(self.recommend_freq, axis=0)[0] #Threshold for number of recommendations\n",
    "        num_click_med = np.median(self.recommend_freq, axis=0)[1] #Threshold for number of clicks\n",
    "        \n",
    "        if self.recommend_freq[action][0] > recommend_freq_med and self.recommend_freq[action][1] < num_click_med:\n",
    "            self.product_weights[action] = 1\n",
    "            action = choices(range(self.config.num_products), weights=self.product_weights, k=1).pop()\n",
    "        \n",
    "        return {\n",
    "            **super().act(observation, reward, done),\n",
    "            **{\n",
    "                'a': action,\n",
    "                'ps': self.product_weights[action] / sum(self.product_weights),\n",
    "                'ps-a': self.product_weights / sum(self.product_weights)\n",
    "            }\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with 1000 users\n"
     ]
    }
   ],
   "source": [
    "import gym, recogym\n",
    "from recogym import env_1_args, Configuration\n",
    "from copy import deepcopy\n",
    "from recogym.evaluate_agent import verify_agents, plot_verify_agents\n",
    "\n",
    "env_1_args['random_seed'] = 42\n",
    "\n",
    "env = gym.make('reco-gym-v1')\n",
    "env.init_gym(env_1_args)\n",
    "\n",
    "# Import the random agent.\n",
    "from recogym.agents import RandomAgent, random_args\n",
    "\n",
    "# Create the two agents.\n",
    "num_products = env_1_args['num_products']\n",
    "bandit_agent_a = BanditAgentA(Configuration(env_1_args))\n",
    "bandit_agent_b = BanditAgentB(Configuration(env_1_args))\n",
    "bandit_agent_rec = BanditAgentRecFreq(Configuration(env_1_args))\n",
    "random_agent = RandomAgent(Configuration({\n",
    "    **env_1_args,\n",
    "    **random_args,\n",
    "}))\n",
    "\n",
    "# Train the bandit agent\n",
    "num_offline_users = 1000\n",
    "num_online_users = 1000\n",
    "print(f'Training with {num_offline_users} users')\n",
    "for useri in range(num_offline_users):\n",
    "\n",
    "    # Reset env and set done to False.\n",
    "    env.reset()\n",
    "    done = False\n",
    "\n",
    "    observation, reward, done = None, 0, False\n",
    "    while not done:\n",
    "        old_observation = observation\n",
    "        action, observation, reward, done, info = env.step_offline(observation, reward, done)\n",
    "        bandit_agent_a.train(old_observation, action, reward, done)\n",
    "        bandit_agent_b.train(old_observation, action, reward, done)\n",
    "        bandit_agent_rec.train(old_observation, action, reward, done)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Agent Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Agent     0.025     0.500     0.975\n",
      "0            CTR Bandit  0.011072  0.011804  0.012567\n",
      "1  Reinforcement Bandit  0.014033  0.014865  0.015729\n",
      "2          Random agent  0.010818  0.011548  0.012311\n",
      "3  Recommendation based  0.014020  0.014852  0.015716\n"
     ]
    }
   ],
   "source": [
    "# Verify the agents\n",
    "env_1_args['random_seed'] = 42\n",
    "new_env = gym.make('reco-gym-v1')\n",
    "new_env.init_gym(env_1_args)\n",
    "result = verify_agents(new_env,\n",
    "                       num_online_users,\n",
    "                       {\n",
    "                           'CTR Bandit': bandit_agent_b,\n",
    "                           'Reinforcement Bandit': bandit_agent_a,\n",
    "                           'Random agent': random_agent,\n",
    "                           'Recommendation based': bandit_agent_rec\n",
    "                       })\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plot_verify_agents(result)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Older work (tests, tuning, ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results (manual)\n",
    "reward - punishment - scores\n",
    "```\n",
    "1.50 - 1.50 - (0.013994055869064171, 0.013171884239367734, 0.014849254638899079)\n",
    "1.75 - 1.25 - (0.014003945889044578, 0.013182341474947828, 0.0148585063756147)\n",
    "1.99 - 1.01 - (0.014008953966975324, 0.01318705769572728,  0.014863817756372355)\n",
    "1.01 - 1.01 - (0.011521147715471919, 0.010782573106312417, 0.012292302808081579)\n",
    "2.00 - 2.00 - (0.013989690193723066, 0.013168154951966047, 0.014844211295086618)\n",
    "1.50 - 1.00 - (0.013942676922602393, 0.013123122930160163, 0.014795171507556604)\n",
    "1.95 - 1.05 - (0.013978205368534297, 0.01315734006691718,  0.014832030229353088)\n",
    "3.00 - 1.10 - (0.013978205368534297, 0.01315734006691718, 0.014832030229353088)\n",
    "1.98 - 1.01 - (0.01397922984435104, 0.013158685574726737, 0.014832704827731802)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning (how much to reward / punish)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start: Agent Training #0\n",
      "Start: Agent Testing #0\n",
      "End: Agent Testing #0 (17.25397825241089s)\n",
      "Start: Agent Training #0\n",
      "Start: Agent Testing #0\n",
      "End: Agent Testing #0 (19.518059492111206s)\n",
      "Start: Agent Training #0\n",
      "Start: Agent Testing #0\n",
      "End: Agent Testing #0 (19.082467079162598s)\n",
      "Start: Agent Training #0\n",
      "Start: Agent Testing #0\n",
      "End: Agent Testing #0 (18.70867395401001s)\n",
      "Start: Agent Training #0\n",
      "Start: Agent Testing #0\n",
      "End: Agent Testing #0 (19.223085641860962s)\n",
      "Start: Agent Training #0\n",
      "Start: Agent Testing #0\n",
      "End: Agent Testing #0 (19.28720259666443s)\n",
      "Start: Agent Training #0\n",
      "Start: Agent Testing #0\n",
      "End: Agent Testing #0 (18.157710075378418s)\n",
      "Start: Agent Training #0\n",
      "Start: Agent Testing #0\n",
      "End: Agent Testing #0 (17.238532543182373s)\n",
      "Start: Agent Training #0\n",
      "Start: Agent Testing #0\n",
      "End: Agent Testing #0 (17.084410190582275s)\n",
      "Start: Agent Training #0\n",
      "Start: Agent Testing #0\n",
      "End: Agent Testing #0 (17.368014812469482s)\n",
      "Start: Agent Training #0\n",
      "Start: Agent Testing #0\n",
      "End: Agent Testing #0 (17.295707941055298s)\n"
     ]
    }
   ],
   "source": [
    "import gym, recogym\n",
    "from recogym import env_1_args, Configuration\n",
    "from copy import deepcopy\n",
    "\n",
    "env_1_args['random_seed'] = 42\n",
    "env = gym.make('reco-gym-v1')\n",
    "env.init_gym(env_1_args)\n",
    "\n",
    "num_products = env_1_args['num_products']\n",
    "bandit_agent_a = BanditAgentA(Configuration(env_1_args))\n",
    "\n",
    "parameters = [\n",
    "    (1.50, 1.50),\n",
    "    (1.75, 1.25),\n",
    "    (1.99, 1.01),\n",
    "    (1.98, 1.02),\n",
    "    (1.01, 1.01),\n",
    "    (2.00, 2.00),\n",
    "    (1.50, 1.00),\n",
    "    (1.95, 1.05),\n",
    "    (3.00, 1.10),\n",
    "    (5.00, 2.00),\n",
    "    (5.00, 1.00)\n",
    "]\n",
    "results = {}\n",
    "\n",
    "for reward, punish in parameters:\n",
    "    # Set reward & punish parameters\n",
    "    bandit_agent_a.factor_reward = reward\n",
    "    bandit_agent_a.factor_punish = punish\n",
    "    \n",
    "    # Run tests\n",
    "    result = recogym.test_agent(deepcopy(env), deepcopy(bandit_agent_a), 1000, 1000)\n",
    "    results[(reward, punish)] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.5, 1.5) - (0.013887907208452902, 0.013069263722806184, 0.014739553504537817)\n",
      "(1.75, 1.25) - (0.014007542089064936, 0.013186108590391916, 0.014861908743926122)\n",
      "(1.99, 1.01) - (0.013978205368534297, 0.01315734006691718, 0.014832030229353088)\n",
      "(1.98, 1.02) - (0.013978205368534297, 0.01315734006691718, 0.014832030229353088)\n",
      "(1.01, 1.01) - (0.011269686199074699, 0.010536946831149873, 0.012035238546886817)\n",
      "(2.0, 2.0) - (0.013978205368534297, 0.01315734006691718, 0.014832030229353088)\n",
      "(1.5, 1.0) - (0.0139457378463552, 0.013125241616100644, 0.014799244346239915)\n",
      "(1.95, 1.05) - (0.013978205368534297, 0.01315734006691718, 0.014832030229353088)\n",
      "(3.0, 1.1) - (0.013978205368534297, 0.01315734006691718, 0.014832030229353088)\n",
      "(5.0, 2.0) - (0.013978205368534297, 0.01315734006691718, 0.014832030229353088)\n",
      "(5.0, 1.0) - (0.013978205368534297, 0.01315734006691718, 0.014832030229353088)\n",
      "\n",
      "Best result (only median is shown):\n",
      "(1.75, 1.25) - 0.014007542089064936\n"
     ]
    }
   ],
   "source": [
    "for k, v in results.items():\n",
    "    print(f'{k} - {v}')\n",
    "\n",
    "best_median = None\n",
    "for m,_,_ in results.values():\n",
    "    if best_median is None or m > best_median:\n",
    "        best_median = m\n",
    "\n",
    "print(\"\\nBest result (only median is shown):\")\n",
    "for k,v in results.items():\n",
    "    if v[0] == best_median:\n",
    "        print(f'{k} - {v[0]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
